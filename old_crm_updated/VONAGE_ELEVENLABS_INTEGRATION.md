# VONAGE_ELEVENLABS_INTEGRATION.md ðŸ”Œ (INTEGRATION GUIDE)

**Ziel:** Telefonie Ã¼ber **Vonage** annehmen und die **ElevenLabs Agents/Voice** als â€žSarahâ€œ sprechen lassen.  
Dieses Dokument ist ein praxisnaher Leitfaden (ohne Secrets), den du in deiner Infrastruktur umsetzen kannst.

> Hinweis: APIs/Details kÃ¶nnen sich Ã¤ndern. PrÃ¼fe die aktuellen Vonage- und ElevenLabs-Dokumentationen und passe Endpoints/Parameter entsprechend an.

---

## Architektur (High-Level)

```
Inbound Call (PSTN)
  -> Vonage Number
    -> Vonage Voice Webhook (NCCO / Call Control)
      -> Deine App (Webserver)
        -> ElevenLabs Agent (Dialog / TTS)
      <- Audio zurÃ¼ck (Stream/Play)
```

**Wichtigste Bausteine:**
- Vonage: Telefonnummer + Voice Application + Webhooks
- Dein Server: Webhook-Endpunkte (Answer/Event), Session-State, Audio-BrÃ¼cke
- ElevenLabs: Agent/Voice Konfiguration, ggf. Streaming/TTS

---

## Voraussetzungen

- Vonage Account (Voice API aktiviert)
- Vonage Telefonnummer
- Vonage Voice Application (mit Webhook URLs)
- ElevenLabs Account + (optional) Agent-ID
- Ã–ffentliche HTTPS-URL fÃ¼r deine Webhooks (z. B. via Reverse Proxy)

---

## Konfiguration (Environment Variablen)

> Keine Secrets committen. Nutze `.env.local` oder Secret Manager.

```bash
# Vonage
VONAGE_API_KEY="..."
VONAGE_API_SECRET="..."
VONAGE_APPLICATION_ID="..."
VONAGE_PRIVATE_KEY_PATH="/secure/path/private.key"

# ElevenLabs
ELEVENLABS_API_KEY="..."
ELEVENLABS_AGENT_ID="..."         # falls Agents genutzt werden
ELEVENLABS_VOICE_ID="..."         # falls klassische TTS Voice genutzt wird

# Public URL
PUBLIC_BASE_URL="https://your-domain.example"
```

---

## Vonage: Voice Application & Webhooks

In Vonage legst du eine **Voice Application** an und setzt:
- **Answer URL**: `PUBLIC_BASE_URL + /webhooks/vonage/answer`
- **Event URL**: `PUBLIC_BASE_URL + /webhooks/vonage/event`

### Answer Webhook (NCCO)
Beim â€žAnswerâ€œ erwartest du ein NCCO, das z. B.:
- eine BegrÃ¼ÃŸung abspielt oder
- direkt einen **Stream**/â€žconnectâ€œ zu deinem Audio/WS-Endpoint herstellt (je nach Vonage Feature/Plan).

Beispiel (konzeptionell):

```json
[
  {
    "action": "talk",
    "text": "Hallo, hier ist Sarah Hoffmann. Passt es gerade 30 Sekunden?"
  }
]
```

> FÃ¼r echte Agent-Dialoge brauchst du typischerweise eine Audio-BrÃ¼cke (Stream/WS) oder du spielst TTS-Antworten sequenziell ab, wÃ¤hrend du parallel Speech-to-Text verarbeitest. Welche Variante mÃ¶glich ist, hÃ¤ngt von deinen Vonage/ElevenLabs Features ab.

---

## ElevenLabs: Agent vs. klassische TTS

### Option A: ElevenLabs Agent (Dialog-Engine)
**Pros:** Dialoglogik + Stil im Prompt, weniger eigener State.  
**Cons:** Integration hÃ¤ngt vom Agent-Interface (Audio/Text/Streaming) ab.

Empfehlung:
- Lege den Agenten â€žSolar-Beraterin Sarahâ€œ in ElevenLabs an
- Nutze den Prompt aus `old_crm_updated/ELEVENLABS_TELESALES_AGENT_PROMPT.md`
- Lies Antworten als Audio aus und spiele sie im Call ab

### Option B: Eigene Dialoglogik + ElevenLabs TTS
**Pros:** Volle Kontrolle Ã¼ber GesprÃ¤chslogik/Policies.  
**Cons:** Mehr Engineering: STT, Turn-Taking, State, Rate Limiting.

---

## Turn-Taking (wer spricht wann?)

Damit Telefonate natÃ¼rlich wirken, brauchst du eine klare Turn-Logik:
- **Listening Mode:** Nutzer spricht â†’ STT transkribiert
- **Thinking Mode:** Prompt/Policy â†’ Antwort generieren
- **Speaking Mode:** ElevenLabs TTS/Agent â†’ Audio abspielen

**Praktische Regeln:**
- Warte nach Nutzer-Satzende ~600â€“900ms, bevor du antwortest (dein â€žResponse Delayâ€œ).
- KÃ¼rze Antworten (1â€“2 SÃ¤tze), stelle 1 Frage pro Turn.
- Bei Overlap (Nutzer spricht wÃ¤hrend Sarah spricht): Audio stoppen und zurÃ¼ck in Listening.

---

## Webhook-Endpunkte (Server)

Du brauchst typischerweise:
- `POST /webhooks/vonage/answer` â†’ liefert NCCO zurÃ¼ck
- `POST /webhooks/vonage/event` â†’ Call-Events (answered, completed, dtmf, etc.)

Optional (wenn Streaming genutzt wird):
- `GET /webhooks/vonage/stream` oder `WS /webhooks/vonage/ws` â†’ Audio rein/raus

### Session-State
Pro Call speicherst du minimal:
- `callId`
- `conversationId` (falls ElevenLabs Agent Sessions nutzt)
- zuletzt erkannte Nutzer-Intention/Phase (1â€“6)
- Timing (letzte AktivitÃ¤t, Timeout)

---

## Sicherheit

- **Webhook-Validierung**: PrÃ¼fe, ob Requests von Vonage stammen (Signaturen/Headers, falls verfÃ¼gbar).
- **Rate Limiting**: Schutz gegen Missbrauch.
- **PII-Minimierung**: Nur notwendige Daten loggen (kein Vollmitschnitt ohne Rechtsgrundlage).
- **Secrets**: nie im Repo, nur als Env/Secret Manager.

---

## Debugging-Checklist

- Kommt `answer` an? (HTTP 200, korrektes NCCO)
- Kommt `event` an? (Call Lifecycle sichtbar)
- Werden TTS/Agent Antworten erzeugt? (Logs, Status Codes)
- Klingt Audio sauber? (Format/Codec korrekt, Latenz ok)
- Abbruch/â€žStopâ€œ-WÃ¼nsche werden respektiert? (sofort beenden)

---

## Minimaler Integrationsablauf (konzeptionell)

1. Call kommt rein â†’ Vonage ruft `answer` auf  
2. Dein Server antwortet mit NCCO (z. B. kurzer â€žtalkâ€œ oder Stream connect)  
3. Nutzer spricht â†’ STT (dein Service oder Provider)  
4. Text â†’ ElevenLabs Agent (oder LLM + TTS)  
5. Audio â†’ im Call abspielen  
6. Wiederholen, bis Termin vereinbart oder Nutzer stoppt

